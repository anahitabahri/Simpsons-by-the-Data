simpsons_data %>%
filter(speaking_line == "true") %>%
group_by(raw_character_text) %>%
summarise(word_count = sum(word_count, na.rm = TRUE),
ep_count = n_distinct(episode_id)) %>%
top_n(n = 10, wt = word_count) %>%
ggplot +
geom_bar(aes(raw_character_text, word_count), stat = "identity") +
coord_flip() +
labs(x = "Character", y = "Total Word Count") +
ggtitle("The Simpsons Top 10 Characters by Number of Spoken Words") +
theme_tws_simpsons()
# ggsave("charts/Top10Characters.png",dpi = 500)
library(scales)
# use dplyr to get sum(word_count) and distinct(episode_id) grouped by characters
simpsons_data %>%
filter(speaking_line == "true") %>%
group_by(raw_character_text) %>%
summarise(word_count = sum(word_count, na.rm = TRUE),
ep_count = n_distinct(episode_id)) %>%
top_n(n = 10, wt = word_count) %>%
ggplot +
geom_bar(aes(raw_character_text, word_count), stat = "identity") +
coord_flip() +
labs(x = "Character", y = "Total Word Count") +
ggtitle("The Simpsons Top 10 Characters by Number of Spoken Words") +
theme_tws_simpsons()
# ggsave("charts/Top10Characters.png",dpi = 500)
library(tidytext)
# use dplyr to get sum(word_count) and distinct(episode_id) grouped by characters
simpsons_data %>%
filter(speaking_line == "true") %>%
group_by(raw_character_text) %>%
summarise(word_count = sum(word_count, na.rm = TRUE),
ep_count = n_distinct(episode_id)) %>%
top_n(n = 10, wt = word_count) %>%
ggplot +
geom_bar(aes(raw_character_text, word_count), stat = "identity") +
coord_flip() +
labs(x = "Character", y = "Total Word Count") +
ggtitle("The Simpsons Top 10 Characters by Number of Spoken Words") +
theme_tws_simpsons()
# ggsave("charts/Top10Characters.png",dpi = 500)
library(lubridate)
library(lubridate)
# use dplyr to get sum(word_count) and distinct(episode_id) grouped by characters
simpsons_data %>%
filter(speaking_line == "true") %>%
group_by(raw_character_text) %>%
summarise(word_count = sum(word_count, na.rm = TRUE),
ep_count = n_distinct(episode_id)) %>%
top_n(n = 10, wt = word_count) %>%
ggplot +
geom_bar(aes(raw_character_text, word_count), stat = "identity") +
coord_flip() +
labs(x = "Character", y = "Total Word Count") +
ggtitle("The Simpsons Top 10 Characters by Number of Spoken Words") +
theme_tws_simpsons()
# ggsave("charts/Top10Characters.png",dpi = 500)
library(stringr)
# use dplyr to get sum(word_count) and distinct(episode_id) grouped by characters
simpsons_data %>%
filter(speaking_line == "true") %>%
group_by(raw_character_text) %>%
summarise(word_count = sum(word_count, na.rm = TRUE),
ep_count = n_distinct(episode_id)) %>%
top_n(n = 10, wt = word_count) %>%
ggplot +
geom_bar(aes(raw_character_text, word_count), stat = "identity") +
coord_flip() +
labs(x = "Character", y = "Total Word Count") +
ggtitle("The Simpsons Top 10 Characters by Number of Spoken Words") +
theme_tws_simpsons()
# ggsave("charts/Top10Characters.png",dpi = 500)
library(grid)
# use dplyr to get sum(word_count) and distinct(episode_id) grouped by characters
simpsons_data %>%
filter(speaking_line == "true") %>%
group_by(raw_character_text) %>%
summarise(word_count = sum(word_count, na.rm = TRUE),
ep_count = n_distinct(episode_id)) %>%
top_n(n = 10, wt = word_count) %>%
ggplot +
geom_bar(aes(raw_character_text, word_count), stat = "identity") +
coord_flip() +
labs(x = "Character", y = "Total Word Count") +
ggtitle("The Simpsons Top 10 Characters by Number of Spoken Words") +
theme_tws_simpsons()
# ggsave("charts/Top10Characters.png",dpi = 500)
library(gridExtra)
# use dplyr to get sum(word_count) and distinct(episode_id) grouped by characters
simpsons_data %>%
filter(speaking_line == "true") %>%
group_by(raw_character_text) %>%
summarise(word_count = sum(word_count, na.rm = TRUE),
ep_count = n_distinct(episode_id)) %>%
top_n(n = 10, wt = word_count) %>%
ggplot +
geom_bar(aes(raw_character_text, word_count), stat = "identity") +
coord_flip() +
labs(x = "Character", y = "Total Word Count") +
ggtitle("The Simpsons Top 10 Characters by Number of Spoken Words") +
theme_tws_simpsons()
# ggsave("charts/Top10Characters.png",dpi = 500)
source("helpers.R")
library(tidyr) # tidy data
library(dplyr) # data manipulation
library(readr) # read files
library(ggplot2) # data viz!
library(ggthemes) # data viz!
library(sqldf) # incorporate sql queries when dplyr doesn't work out
characters <- read_csv("data/simpsons_characters.csv")
episodes <- read_csv("data/simpsons_episodes.csv")
locations <- read_csv("data/simpsons_locations.csv")
lines <- read_csv("data/simpsons_script_lines.csv")
colnames(lines) # we care about character_id
colnames(characters) # we care about id
# using dplyr's left_join, join all the datasets!
simpsons_data <- left_join(lines, locations, by = c("location_id" = "id"))
simpsons_data <- left_join(simpsons_data, episodes, by = c("episode_id" = "id"))
simpsons_data <- left_join(simpsons_data, characters, by = c("character_id" = "id"))
colnames(simpsons_data)
# there are way too many cols here. let's trim it down to a select few.
simpsons_data <- select(simpsons_data, id, episode_id, number, timestamp_in_ms, speaking_line, raw_character_text, raw_location_text, normalized_text, word_count, title, original_air_date, season, number_in_season, number_in_series, us_viewers_in_millions, views, imdb_rating, gender)
class(simpsons_data$word_count)
# need to change data type of word count to numeric
simpsons_data$word_count <- as.numeric(simpsons_data$word_count)
# check other relevant data types
class(simpsons_data$us_viewers_in_millions)
class(simpsons_data$views)
class(simpsons_data$imdb_rating)
library("rio")
install.packages("rio")
library("rio")
export(simpsons_data, "simpsons_data.csv")
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, comment = FALSE)
library(tidyr) # tidy data
library(dplyr) # data manipulation
library(readr) # read files
library(ggplot2) # data viz!
library(ggthemes) # data viz!
library(sqldf) # incorporate sql queries when dplyr doesn't work out
characters <- read_csv("data/simpsons_characters.csv")
episodes <- read_csv("data/simpsons_episodes.csv")
locations <- read_csv("data/simpsons_locations.csv")
lines <- read_csv("data/simpsons_script_lines.csv")
colnames(lines) # we care about character_id
colnames(characters) # we care about id
# using dplyr's left_join, join all the datasets!
simpsons_data <- left_join(lines, locations, by = c("location_id" = "id"))
simpsons_data <- left_join(simpsons_data, episodes, by = c("episode_id" = "id"))
simpsons_data <- left_join(simpsons_data, characters, by = c("character_id" = "id"))
colnames(simpsons_data)
# there are way too many cols here. let's trim it down to a select few.
simpsons_data <- select(simpsons_data, id, episode_id, number, timestamp_in_ms, speaking_line, raw_character_text, raw_location_text, normalized_text, word_count, title, original_air_date, season, number_in_season, number_in_series, us_viewers_in_millions, views, imdb_rating, gender)
class(simpsons_data$word_count)
# need to change data type of word count to numeric
simpsons_data$word_count <- as.numeric(simpsons_data$word_count)
# check other relevant data types
class(simpsons_data$us_viewers_in_millions)
class(simpsons_data$views)
class(simpsons_data$imdb_rating)
# use dplyr to get sum(word_count) and distinct(episode_id) grouped by characters
simpsons_data %>%
filter(speaking_line == "true") %>%
group_by(raw_character_text) %>%
summarise(word_count = sum(word_count, na.rm = TRUE),
ep_count = n_distinct(episode_id)) %>%
top_n(n = 10, wt = word_count) %>%
ggplot +
geom_bar(aes(raw_character_text, word_count), stat = "identity") +
coord_flip() +
labs(x = "Character", y = "Total Word Count") +
ggtitle("The Simpsons Top 10 Characters by Number of Spoken Words") +
theme_minimal()
ggsave("charts/Top10Characters.png",dpi = 500)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, comment = FALSE)
library(tidyr) # tidy data
library(dplyr) # data manipulation
library(readr) # read files
library(ggplot2) # data viz!
library(ggthemes) # data viz!
library(sqldf) # incorporate sql queries when dplyr doesn't work out
options(scipen=999)
characters <- read_csv("data/simpsons_characters.csv")
episodes <- read_csv("data/simpsons_episodes.csv")
locations <- read_csv("data/simpsons_locations.csv")
lines <- read_csv("data/simpsons_script_lines.csv")
colnames(lines) # we care about character_id
colnames(characters) # we care about id
# using dplyr's left_join, join all the datasets!
simpsons_data <- left_join(lines, locations, by = c("location_id" = "id"))
simpsons_data <- left_join(simpsons_data, episodes, by = c("episode_id" = "id"))
simpsons_data <- left_join(simpsons_data, characters, by = c("character_id" = "id"))
colnames(simpsons_data)
# there are way too many cols here. let's trim it down to a select few.
simpsons_data <- select(simpsons_data, id, episode_id, number, timestamp_in_ms, speaking_line, raw_character_text, raw_location_text, normalized_text, word_count, title, original_air_date, season, number_in_season, number_in_series, us_viewers_in_millions, views, imdb_rating, gender)
class(simpsons_data$word_count)
# need to change data type of word count to numeric
simpsons_data$word_count <- as.numeric(simpsons_data$word_count)
# check other relevant data types
class(simpsons_data$us_viewers_in_millions)
class(simpsons_data$views)
class(simpsons_data$imdb_rating)
# use dplyr to get sum(word_count) and distinct(episode_id) grouped by characters
simpsons_data %>%
filter(speaking_line == "true") %>%
group_by(raw_character_text) %>%
summarise(word_count = sum(word_count, na.rm = TRUE),
ep_count = n_distinct(episode_id)) %>%
top_n(n = 10, wt = word_count) %>%
ggplot +
geom_bar(aes(raw_character_text, word_count), stat = "identity") +
coord_flip() +
labs(x = "Character", y = "Total Word Count") +
ggtitle("The Simpsons Top 10 Characters by Number of Spoken Words") +
theme_minimal()
ggsave("charts/Top10Characters.png",dpi = 500)
# use sqldf to also get sum(word_count), distinct(episode_id), gender (not NA), grouped by characters
words_by_character <- sqldf("SELECT raw_character_text, gender, SUM(word_count) as sum_word_count, COUNT(DISTINCT episode_id) AS episode_count
FROM simpsons_data
WHERE gender IS NOT \"NA\"
GROUP BY raw_character_text
ORDER BY 3 DESC, raw_character_text")
ggplot(words_by_character[1:15, ], aes(raw_character_text, sum_word_count, fill = gender)) +
geom_bar(stat = "identity") +
coord_flip() +
ggtitle("The Simpsons Top 15 Characters by Number of Spoken Words")+
labs(x = "Character", y = "Total Word Count") +
theme_minimal()
ggsave("charts/Top15Characters_Gender.png",dpi = 500)
# use sqldf to also get sum(word_count), distinct(episode_id), gender (not NA), grouped by characters
words_by_character <- sqldf("SELECT raw_character_text, gender, SUM(word_count) as sum_word_count, COUNT(DISTINCT episode_id) AS episode_count
FROM simpsons_data
WHERE gender IS NOT \"NA\" and raw_character_test IS NOT \"NA\"
GROUP BY raw_character_text
ORDER BY 3 DESC, raw_character_text")
colnames(lines) # we care about character_id
colnames(characters) # we care about id
# using dplyr's left_join, join all the datasets!
simpsons_data <- left_join(lines, locations, by = c("location_id" = "id"))
simpsons_data <- left_join(simpsons_data, episodes, by = c("episode_id" = "id"))
simpsons_data <- left_join(simpsons_data, characters, by = c("character_id" = "id"))
colnames(simpsons_data)
# there are way too many cols here. let's trim it down to a select few.
simpsons_data <- select(simpsons_data, id, episode_id, number, timestamp_in_ms, speaking_line, raw_character_text, raw_location_text, normalized_text, word_count, title, original_air_date, season, number_in_season, number_in_series, us_viewers_in_millions, views, imdb_rating, gender)
class(simpsons_data$word_count)
# need to change data type of word count to numeric
simpsons_data$word_count <- as.numeric(simpsons_data$word_count)
# check other relevant data types
class(simpsons_data$us_viewers_in_millions)
class(simpsons_data$views)
class(simpsons_data$imdb_rating)
# use sqldf to also get sum(word_count), distinct(episode_id), gender (not NA), grouped by characters
words_by_character <- sqldf("SELECT raw_character_text, gender, SUM(word_count) as sum_word_count, COUNT(DISTINCT episode_id) AS episode_count
FROM simpsons_data
WHERE gender IS NOT \"NA\" and raw_character_text IS NOT \"NA\"
GROUP BY raw_character_text
ORDER BY 3 DESC, raw_character_text")
ggplot(words_by_character[1:15, ], aes(raw_character_text, sum_word_count, fill = gender)) +
geom_bar(stat = "identity") +
coord_flip() +
ggtitle("The Simpsons Top 15 Characters by Number of Spoken Words")+
labs(x = "Character", y = "Total Word Count") +
theme_minimal()
ggsave("charts/Top15Characters_Gender.png",dpi = 500)
# use sqldf to also get sum(word_count), distinct(episode_id), gender (not NA), grouped by characters
words_by_character <- sqldf("SELECT raw_character_text, gender, SUM(word_count) as sum_word_count, COUNT(DISTINCT episode_id) AS episode_count
FROM simpsons_data
WHERE gender IS NOT \"NA\"
GROUP BY raw_character_text
ORDER BY 3 DESC, raw_character_text")
View(words_by_character)
words_by_character <- sqldf("SELECT raw_character_text, gender, SUM(word_count) as sum_word_count, COUNT(DISTINCT episode_id) AS episode_count
FROM simpsons_data
GROUP BY raw_character_text
ORDER BY 3 DESC, raw_character_text")
words_by_character <- na.omit(words_by_character)
View(words_by_character) # there's an NA.
ggplot(words_by_character[1:15, ], aes(raw_character_text, sum_word_count, fill = gender)) +
geom_bar(stat = "identity") +
coord_flip() +
ggtitle("The Simpsons Top 15 Characters by Number of Spoken Words")+
labs(x = "Character", y = "Total Word Count") +
theme_minimal()
ggsave("charts/Top15Characters_Gender.png",dpi = 500)
ggplot(words_by_character[1:20, ], aes(raw_character_text, sum_word_count, fill = gender)) +
geom_bar(stat = "identity") +
coord_flip() +
ggtitle("The Simpsons Top 20 Characters by Number of Spoken Words")+
labs(x = "Character", y = "Total Word Count") +
theme_minimal()
ggsave("charts/Top20Characters_Gender.png",dpi = 500)
# use sqldf to group a dataframe similar to words_by_character by raw_location_text
words_by_location <- sqldf("SELECT raw_character_text, gender, SUM(word_count) as sum_word_count, COUNT(DISTINCT episode_id) AS episode_count, raw_location_text
FROM simpsons_data
WHERE gender IS NOT \"NA\"
GROUP BY raw_location_text
ORDER BY 3 DESC, raw_location_text")
ggplot(words_by_location[1:5, ], aes(raw_location_text, sum_word_count)) +
geom_bar(stat = "identity") +
coord_flip() +
ggtitle("The Top 5 Locations by Number of Spoken Words")+
labs(x = "Location", y = "Total Word Count") +
theme_minimal()
ggsave("charts/Top5Locations.png",dpi = 500)
ggplot(simpsons_data, aes(original_air_date,us_viewers_in_millions)) +
geom_point(color="#E77471",alpha=0.1) +
geom_smooth(color="black") +
ggtitle("The Simpsons TV Viewers by episode") +
labs(x = "Original Air Date", y = "US Viewers in Millions")
ggsave("charts/ViewersByEpisode.png",dpi = 500)
# viewership has gone down substantialy over the years. how about episode ratings over the years?
lm(simpsons_data$us_viewers_in_millions ~ simpsons_data$original_air_date)
ggplot(simpsons_data, aes(original_air_date,imdb_rating)) +
geom_point(color="#E77471",alpha=0.1) +
geom_smooth(color="black") +
ggtitle("The Simpsons TV ratings by episode") +
labs(x = "Original Air Date", y = "IMDB Rating")
ggsave("charts/RatingsByEpisode.png",dpi = 500)
# ratings have also gone down slightly over the years, but not as drastically as viewers. why may this be the case? the rise of tv streaming!
lm(simpsons_data$imdb_rating ~ simpsons_data$original_air_date)
simpsons_data <- left_join(lines, locations, by = c("location_id" = "id"))
simpsons_data <- left_join(simpsons_data, episodes, by = c("episode_id" = "id"))
simpsons_data <- left_join(simpsons_data, characters, by = c("character_id" = "id"))
simpsons_data <- select(simpsons_data, id, episode_id, number, timestamp_in_ms, speaking_line, raw_character_text, raw_location_text, normalized_text, word_count, title, original_air_date, season, number_in_season, number_in_series, us_viewers_in_millions, views, imdb_rating, gender)
class(simpsons_data$word_count)
simpsons_data$word_count <- as.numeric(simpsons_data$word_count)
class(simpsons_data$us_viewers_in_millions)
class(simpsons_data$views)
class(simpsons_data$imdb_rating)
simpsons_data %>%
filter(speaking_line == "true") %>%
group_by(raw_character_text) %>%
summarise(word_count = sum(word_count, na.rm = TRUE),
ep_count = n_distinct(episode_id)) %>%
top_n(n = 10, wt = word_count) %>%
ggplot +
geom_bar(aes(raw_character_text, word_count), stat = "identity") +
coord_flip() +
labs(x = "Character", y = "Total Word Count") +
ggtitle("The Simpsons Top 10 Characters by Number of Spoken Words") +
theme_minimal()
ggsave("charts/Top10Characters.png",dpi = 500)
simpsons_data %>%
filter(speaking_line == "true") %>%
group_by(raw_character_text) %>%
summarise(word_count = sum(word_count, na.rm = TRUE),
ep_count = n_distinct(episode_id)) %>%
top_n(n = 10, wt = word_count) %>%
ggplot +
geom_bar(aes(raw_character_text, word_count), stat = "identity") +
coord_flip() +
labs(x = "Character", y = "Total Word Count") +
ggtitle("The Simpsons Top 10 Characters by Number of Spoken Words") +
theme_minimal()
words_by_character <- sqldf("SELECT raw_character_text, gender, SUM(word_count) as sum_word_count, COUNT(DISTINCT episode_id) AS episode_count
FROM simpsons_data
GROUP BY raw_character_text
ORDER BY 3 DESC, raw_character_text")
words_by_character <- na.omit(words_by_character)
ggplot(words_by_character[1:15, ], aes(raw_character_text, sum_word_count, fill = gender)) +
geom_bar(stat = "identity") +
coord_flip() +
ggtitle("The Simpsons Top 15 Characters by Number of Spoken Words")+
labs(x = "Character", y = "Total Word Count") +
theme_minimal()
ggsave("charts/Top15Characters_Gender.png",dpi = 500)
ggplot(words_by_character[1:20, ], aes(raw_character_text, sum_word_count, fill = gender)) +
geom_bar(stat = "identity") +
coord_flip() +
ggtitle("The Simpsons Top 20 Characters by Number of Spoken Words")+
labs(x = "Character", y = "Total Word Count") +
theme_minimal()
ggsave("charts/Top20Characters_Gender.png",dpi = 500)
ggplot(words_by_character[1:20, ], aes(raw_character_text, sum_word_count, fill = gender)) +
geom_bar(stat = "identity") +
coord_flip() +
ggtitle("The Simpsons Top 20 Characters by Number of Spoken Words")+
labs(x = "Character", y = "Total Word Count") +
theme_minimal()
words_by_location <- sqldf("SELECT raw_character_text, gender, SUM(word_count) as sum_word_count, COUNT(DISTINCT episode_id) AS episode_count, raw_location_text
FROM simpsons_data
GROUP BY raw_location_text
ORDER BY 3 DESC, raw_location_text")
ggplot(words_by_location[1:5, ], aes(raw_location_text, sum_word_count)) +
geom_bar(stat = "identity") +
coord_flip() +
ggtitle("The Top 5 Locations by Number of Spoken Words")+
labs(x = "Location", y = "Total Word Count") +
theme_minimal()
ggsave("charts/Top5Locations.png",dpi = 500)
ggplot(words_by_location[1:5, ], aes(raw_location_text, sum_word_count)) +
geom_bar(stat = "identity") +
coord_flip() +
ggtitle("The Top 5 Locations by Number of Spoken Words")+
labs(x = "Location", y = "Total Word Count") +
theme_minimal()
ggplot(simpsons_data, aes(original_air_date,us_viewers_in_millions)) +
geom_point(color="#E77471",alpha=0.1) +
geom_smooth(color="black") +
ggtitle("The Simpsons TV Viewers by episode") +
labs(x = "Original Air Date", y = "US Viewers in Millions")
ggplot(simpsons_data, aes(original_air_date,imdb_rating)) +
geom_point(color="#E77471",alpha=0.1) +
geom_smooth(color="black") +
ggtitle("The Simpsons TV ratings by episode") +
labs(x = "Original Air Date", y = "IMDB Rating")
ggsave("charts/RatingsByEpisode.png",dpi = 500)
ggsave("charts/ViewersByEpisode.png",dpi = 500)
ggplot(simpsons_data, aes(original_air_date,us_viewers_in_millions)) +
geom_point(color="#E77471",alpha=0.1) +
geom_smooth(color="black") +
ggtitle("The Simpsons TV Viewers by episode") +
labs(x = "Original Air Date", y = "US Viewers in Millions")
ggsave("charts/ViewersByEpisode.png",dpi = 500)
lm(simpsons_data$us_viewers_in_millions ~ simpsons_data$original_air_date)
ggplot(simpsons_data, aes(original_air_date,us_viewers_in_millions)) +
geom_point(color="#E77471",alpha=0.1) +
geom_smooth(color="black") +
ggtitle("The Simpsons TV Viewers by episode") +
labs(x = "Original Air Date", y = "US Viewers in Millions")
# What's in common in both in the lines and location datasets? Location ID!
# For episodes and characters, it's Episode ID and Character ID, respectively, when compared to the lines dataset.
# If you look at the column names of each of the datasets, you'd notice that these IDs don't have the same name. For example, location ID in the lines dataset is "location_id", while it is "id" in the locations dataset. This is why a vector is created in the following dataset join code. If the column name was "location_id" in both datasets, I'd just need to say 'by = location_id', but that isn't the case here.
# using dplyr's left_join, we join all the datasets!
simpsons_data <- left_join(lines, locations, by = c("location_id" = "id"))
simpsons_data <- left_join(simpsons_data, episodes, by = c("episode_id" = "id"))
simpsons_data <- left_join(simpsons_data, characters, by = c("character_id" = "id"))
colnames(simpsons_data)
# There are way too many columns here, thanks to not trimming it down before. A next step would be to select the relevant columns for analysis using dplyr.
simpsons_data <- select(simpsons_data, id, episode_id, number, timestamp_in_ms, speaking_line, raw_character_text, raw_location_text, normalized_text, word_count, title, original_air_date, season, number_in_season, number_in_series, us_viewers_in_millions, views, imdb_rating, gender)
class(simpsons_data$word_count)
# I plan to do some analysis using word_count, which is currently a character. I need to change its data type to numeric to do any kind of analysis or even visualization.
simpsons_data$word_count <- as.numeric(simpsons_data$word_count)
# Check other relevant data types I plan to do some analysis on.
class(simpsons_data$us_viewers_in_millions)
class(simpsons_data$views)
class(simpsons_data$imdb_rating)
# All of these look good!
# Here I use dplyr to get the total word count and distinct episode ids grouped by characters, which, in turn is used to create a plot using ggplot2.
simpsons_data %>%
filter(speaking_line == "true") %>%
group_by(raw_character_text) %>%
summarise(word_count = sum(word_count, na.rm = TRUE),
ep_count = n_distinct(episode_id)) %>%
top_n(n = 10, wt = word_count) %>%
ggplot +
geom_bar(aes(raw_character_text, word_count), stat = "identity") +
coord_flip() +
labs(x = "Character", y = "Total Word Count") +
ggtitle("The Simpsons Top 10 Characters by Number of Spoken Words") +
theme_minimal()
ggsave("charts/Top10Characters.png",dpi = 500)
# SQLDF is a package that uses SQL syntax. I could do the following using dplyr, but here's a different way to subset the data at hand to get the total word count and total number of episodes grouped by the various characters.
words_by_character <- sqldf("SELECT raw_character_text, gender, SUM(word_count) as sum_word_count, COUNT(DISTINCT episode_id) AS episode_count
FROM simpsons_data
GROUP BY raw_character_text
ORDER BY 3 DESC, raw_character_text")
View(words_by_character) # There's an NA that I'd definitely like to remove.
words_by_character <- na.omit(words_by_character)
ggplot(words_by_character[1:15, ], aes(raw_character_text, sum_word_count, fill = gender)) +
geom_bar(stat = "identity") +
coord_flip() +
ggtitle("The Simpsons Top 15 Characters by Number of Spoken Words")+
labs(x = "Character", y = "Total Word Count") +
theme_minimal()
ggsave("charts/Top15Characters_Gender.png",dpi = 500)
ggplot(words_by_character[1:20, ], aes(raw_character_text, sum_word_count, fill = gender)) +
geom_bar(stat = "identity") +
coord_flip() +
ggtitle("The Simpsons Top 20 Characters by Number of Spoken Words")+
labs(x = "Character", y = "Total Word Count") +
theme_minimal()
ggsave("charts/Top20Characters_Gender.png",dpi = 500)
# Once again, we'll use SQLDF to group a dataframe similar to words_by_character by the location instead.
words_by_location <- sqldf("SELECT raw_character_text, gender, SUM(word_count) as sum_word_count, COUNT(DISTINCT episode_id) AS episode_count, raw_location_text
FROM simpsons_data
GROUP BY raw_location_text
ORDER BY 3 DESC, raw_location_text")
ggplot(words_by_location[1:5, ], aes(raw_location_text, sum_word_count)) +
geom_bar(stat = "identity") +
coord_flip() +
ggtitle("The Top 5 Locations by Number of Spoken Words")+
labs(x = "Location", y = "Total Word Count") +
theme_minimal()
ggsave("charts/Top5Locations.png",dpi = 500)
ggplot(simpsons_data, aes(original_air_date,us_viewers_in_millions)) +
geom_point(color="#E77471",alpha=0.1) +
geom_smooth(color="black") +
ggtitle("The Simpsons TV Viewers by episode") +
labs(x = "Original Air Date", y = "US Viewers in Millions")
ggsave("charts/ViewersByEpisode.png",dpi = 500)
lm(simpsons_data$us_viewers_in_millions ~ simpsons_data$original_air_date)
ggplot(simpsons_data, aes(original_air_date,imdb_rating)) +
geom_point(color="#E77471",alpha=0.1) +
geom_smooth(color="black") +
ggtitle("The Simpsons TV ratings by episode") +
labs(x = "Original Air Date", y = "IMDB Rating")
ggsave("charts/RatingsByEpisode.png",dpi = 500)
lm(simpsons_data$imdb_rating ~ simpsons_data$original_air_date)
words_by_location <- sqldf("SELECT raw_character_text, gender, SUM(word_count) as sum_word_count, COUNT(DISTINCT episode_id) AS episode_count, raw_location_text
FROM simpsons_data
GROUP BY raw_location_text
ORDER BY 3 DESC")
ggplot(words_by_location[1:5, ], aes(raw_location_text, sum_word_count)) +
geom_bar(stat = "identity") +
coord_flip() +
ggtitle("The Top 5 Locations by Number of Spoken Words")+
labs(x = "Location", y = "Total Word Count") +
theme_minimal()
ggsave("charts/Top5Locations.png",dpi = 500)
